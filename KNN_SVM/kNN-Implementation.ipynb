{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# $k$-NN Implementation  \n",
    "* This $k$-Nearest Neighbors is broken down into 3 parts:\n",
    "\n",
    "    1. Step 1: Calculate Euclidean Distance.\n",
    "    2. Step 2: Get Nearest Neighbors.\n",
    "    3. Step 3: Make Predictions.\n",
    "\n",
    "* These steps will teach the fundamentals of implementing and applying the $k$-Nearest Neighbors algorithm for classification and regression predictive modeling problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Step 1: Calculate Euclidean Distance__\n",
    "* Rows of data are mostly made up of numbers and an easy way to calculate the distance between two rows or vectors of numbers is to draw a straight line. This makes sense in 2D or 3D and scales nicely to higher dimensions.\n",
    "* We can calculate the straight line distance between two vectors using the Euclidean distance measure.\n",
    "* With Euclidean distance, the smaller the value, the more similar two records will be. A value of 0 means that there is no difference between two records.\n",
    "* Below is a function named euclidean_distance() that implements this in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "# calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "    print(row1)\n",
    "    print(\"000000000000000000000000000000000000000000000000000\")\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return sqrt(distance)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Step 2: Get Nearest Neighbors__\n",
    "* Neighbors for a new piece of data in the dataset are the $k$ closest instances, as defined by our distance measure.\n",
    "* To locate the neighbors for a new piece of data within a dataset we must first calculate the distance between each record in the dataset to the new piece of data. We can do this using our distance function prepared above.\n",
    "* Once distances are calculated, we must sort all of the records in the training dataset by their distance to the new data. We can then select the top $k$ to return as the most similar neighbors.\n",
    "* We can do this by keeping track of the distance for each record in the dataset as a tuple, sort the list of tuples by the distance (in descending order) and then retrieve the neighbors.\n",
    "* Below is a function named get_neighbors() that implements this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Locate the most similar neighbors\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    distances = list()\n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(test_row, train_row)\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* You can see that the euclidean_distance() function developed in the previous step is used to calculate the distance between each train_row and the new test_row.\n",
    "* The list of train_row and distance tuples is sorted where a custom key is used ensuring that the second item in the tuple (tup[1]) is used in the sorting operation.\n",
    "* Finally, a list of the num_neighbors most similar neighbors to test_row is returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Step 3: Make Predictions__\n",
    "* The most similar neighbors collected from the training dataset can be used to make predictions.\n",
    "* In the case of classification, we can return the most represented class among the neighbors.\n",
    "* We can achieve this by performing the max() function on the list of output values from the neighbors. Given a list of class values observed in the neighbors, the max() function takes a set of unique class values and calls the count on the list of class values for each class value in the set.\n",
    "* Below is the function named predict_classification() that implements this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Make a classification prediction with neighbors\n",
    "def predict_classification(train, test_row, num_neighbors):\n",
    "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "    output_values = [row[-1] for row in neighbors]\n",
    "    prediction = max(set(output_values), key=output_values.count)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Iris Flower Species Dataset Example\n",
    "* In this example we will use the Iris Flower Species Dataset.\n",
    "* The Iris Flower Dataset involves predicting the flower species given measurements of iris flowers.\n",
    "* The number of observations for each class is balanced. There are 150 observations with 4 input variables and 1 output variable. The variable names are as follows:\n",
    "    - Variable 1: Sepal length in cm.\n",
    "    - Variable 2: Sepal width in cm.\n",
    "    - Variable 3: Petal length in cm.\n",
    "    - Variable 4: Petal width in cm.\n",
    "    - Output: Class\n",
    "* 4 input variable and the output are arranged in the file as follows\n",
    "    - Variable 1, Variable 2,Variable 3, Variable 4, output\n",
    "* A sample of the contenet in the file \"iris.csv\" is shown below:<br>\n",
    "5.1,3.5,1.4,0.2,Iris-setosa<br>\n",
    "4.9,3.0,1.4,0.2,Iris-setosa<br>\n",
    "4.7,3.2,1.3,0.2,Iris-setosa<br>\n",
    "4.6,3.1,1.5,0.2,Iris-setosa<br>\n",
    ".... <br>    \n",
    "* The first step is to load the dataset and convert the loaded data to numbers that we can use with the mean and standard deviation calculations. For this we will use the helper function load_csv() to load the file, str_column_to_float() to convert string numbers to floats and str_column_to_int() to convert the class column to integer values.\n",
    "* We will evaluate the algorithm using $k$-fold cross-validation with $k=5$ folds. This means that 150/5=30 records will be in each fold. We will use the helper functions evaluate_algorithm() to evaluate the algorithm with cross-validation and accuracy_metric() to calculate the accuracy of predictions.\n",
    "* A new function named k_nearest_neighbors() was developed to manage the application of the $k$-NN algorithm, first learning the statistics from a training dataset and using them to make predictions for a test dataset.\n",
    "* The complete code for $k$-NN is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [93.33333333333333, 96.66666666666667, 100.0, 93.33333333333333, 96.66666666666667]\n",
      "Mean Accuracy: 96.000%\n"
     ]
    }
   ],
   "source": [
    "# k-nearest neighbors on the Iris Flowers Dataset\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import  reader\n",
    "from math import sqrt\n",
    " \n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "\tdataset = list()\n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tcsv_reader = reader(file)\n",
    "\t\tfor row in csv_reader:\n",
    "\t\t\tif not row:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tdataset.append(row)\n",
    "\treturn dataset\n",
    " \n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = float(row[column].strip())\n",
    " \n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "\tclass_values = [row[column] for row in dataset]\n",
    "\tunique = set(class_values)\n",
    "\tlookup = dict()\n",
    "\tfor i, value in enumerate(unique):\n",
    "\t\tlookup[value] = i\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = lookup[row[column]]\n",
    "\treturn lookup\n",
    " \n",
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "\tminmax = list()\n",
    "\tfor i in range(len(dataset[0])):\n",
    "\t\tcol_values = [row[i] for row in dataset]\n",
    "\t\tvalue_min = min(col_values)\n",
    "\t\tvalue_max = max(col_values)\n",
    "\t\tminmax.append([value_min, value_max])\n",
    "\treturn minmax\n",
    " \n",
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize_dataset(dataset, minmax):\n",
    "\tfor row in dataset:\n",
    "\t\tfor i in range(len(row)):\n",
    "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    " \n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / n_folds)\n",
    "\tfor _ in range(n_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    " \n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "\tcorrect = 0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn correct / float(len(actual)) * 100.0\n",
    " \n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores\n",
    " \n",
    "# Calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "\tdistance = 0.0\n",
    "\tfor i in range(len(row1)-1):\n",
    "\t\tdistance += (row1[i] - row2[i])**2\n",
    "\treturn sqrt(distance)\n",
    " \n",
    "# Locate the most similar neighbors\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "\tprint(test_row)\n",
    "\tdistances = list()\n",
    "\tfor train_row in train:\n",
    "\t\tdist = euclidean_distance(test_row, train_row)\n",
    "\t\tdistances.append((train_row, dist))\n",
    "\tdistances.sort(key=lambda tup: tup[1])\n",
    "\tneighbors = list()\n",
    "\tfor i in range(num_neighbors):\n",
    "\t\tneighbors.append(distances[i][0])\n",
    "\treturn neighbors\n",
    " \n",
    "# Make a prediction with neighbors\n",
    "def predict_classification(train, test_row, num_neighbors):\n",
    "\tneighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "\toutput_values = [row[-1] for row in neighbors]\n",
    "\tprediction = max(set(output_values), key=output_values.count)\n",
    "\treturn prediction\n",
    " \n",
    "# kNN Algorithm\n",
    "def k_nearest_neighbors(train, test, num_neighbors):\n",
    "\tpredictions = list()\n",
    "\tfor row in test:\n",
    "\t\toutput = predict_classification(train, row, num_neighbors)\n",
    "\t\tpredictions.append(output)\n",
    "\treturn(predictions)\n",
    " \n",
    "# Test the kNN on the Iris Flowers dataset\n",
    "seed(1)\n",
    "filename = 'iris.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])-1):\n",
    "\tstr_column_to_float(dataset, i)\n",
    "# convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "num_neighbors = 3\n",
    "scores = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Implementing $k$-NN Algorithm with Scikit-Learn\n",
    "* We will see how Python's Scikit-Learn library can be used to implement the $k$-NN algorithm in less than 20 lines of code. * To download and installation instructions for Scikit learn library please enter the following command in the command prompt:\n",
    "    - pip install -U scikit-learn\n",
    "* Source https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The Dataset\n",
    "\n",
    "* We are going to use the famous iris data set for our $k$-NN example. The dataset consists of four attributes: sepal-width, sepal-length, petal-width and petal-length. These are the attributes of specific types of iris plant. The task is to predict the class to which these plants belong. There are three classes in the dataset: Iris-setosa, Iris-versicolor and Iris-virginica. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Importing the Dataset\n",
    "\n",
    "* To import the dataset and load it into our pandas dataframe, execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "\n",
    "# Assign colum names to the dataset\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
    "\n",
    "# Read dataset to pandas dataframe\n",
    "dataset = pd.read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* To see what the dataset actually looks like, execute the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width        Class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "* The next step is to split our dataset into its attributes and labels. To do so, use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* The X variable contains the first four columns of the dataset (i.e. attributes) while y contains the labels.\n",
    "\n",
    "# Train Test Split\n",
    "\n",
    "* To avoid over-fitting, we will divide our dataset into training and test splits, which gives us a better idea as to how our algorithm performed during the testing phase. This way our algorithm is tested on unseen data, as it would be in a production application.\n",
    "\n",
    "* To create training and test splits, execute the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* The above script splits the dataset into 80% train data and 20% test data. This means that out of total 150 records, the training set will contain 120 records and the test set contains 30 of those records.\n",
    "\n",
    "# Feature Scaling\n",
    "\n",
    "* Before making any actual predictions, it is always a good practice to scale the features so that all of them can be uniformly evaluated.\n",
    "\n",
    "* We do feather scaling since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization. For example, the majority of classifiers calculate the distance between two points by the Euclidean distance. If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance. \n",
    "    - [source: https://en.wikipedia.org/wiki/Feature_scaling#Motivation]\n",
    "* The following script performs feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Training and Predictions\n",
    "\n",
    "* It is extremely straight forward to train the KNN algorithm and make predictions with it, especially when using Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* The first step is to import the KNeighborsClassifier class from the sklearn.neighbors library. In the second line, this class is initialized with one parameter, i.e. n_neigbours. This is basically the value for the K. There is no ideal value for K and it is selected after testing and evaluation, however to start out, 5 seems to be the most commonly used value for KNN algorithm.\n",
    "\n",
    "* The final step is to make predictions on our test data. To do so, execute the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Evaluating the Algorithm\n",
    "\n",
    "* For evaluating an algorithm, confusion matrix, precision, recall and f1 score are the most commonly used metrics. The confusion_matrix and classification_report methods of the sklearn.metrics can be used to calculate these metrics. Take a look at the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0  8  0]\n",
      " [ 0  2  9]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        11\n",
      "Iris-versicolor       0.80      1.00      0.89         8\n",
      " Iris-virginica       1.00      0.82      0.90        11\n",
      "\n",
      "       accuracy                           0.93        30\n",
      "      macro avg       0.93      0.94      0.93        30\n",
      "   weighted avg       0.95      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* The results show that our KNN algorithm was able to classify all the 30 records in the test set with 97% average precision, recall and f1-score, which is very good. Although the algorithm performed very well with this dataset, don't expect the same results with all applications. As noted earlier, KNN doesn't always perform as well with high-dimensionality or categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Error Rate with the K Value\n",
    "\n",
    "* In the training and prediction section we said that there is no way to know beforehand which value of K that yields the best results in the first go. We randomly chose 5 as the K value and it just happen to result in 100% accuracy.\n",
    "\n",
    "* One way to help you find the best value of K is to plot the graph of K value and the corresponding error rate for the dataset.\n",
    "\n",
    "* In this section, we will plot the mean error for the predicted values of test set for all the K values between 1 and 40.\n",
    "\n",
    "* To do so, let's first calculate the mean of error for all the predicted values where K ranges from 1 and 40. Execute the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 40\n",
    "for i in range(1, 40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The above script executes a loop from 1 to 40. In each iteration the mean error for predicted values of test set is calculated and the result is appended to the error list.\n",
    "\n",
    "* The next step is to plot the error values against K values. Execute the following script to create the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean Error')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error') "
   ]
  }
 ],
 "metadata": {
  "author": "Another algorithm template",
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "rise": {
   "scroll": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "234.15px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
